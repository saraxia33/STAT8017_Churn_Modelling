{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Techniques\n",
    "## Assignment 3\n",
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michi\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\michi\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\", index_col=[1])\n",
    "del df['RowNumber']\n",
    "del df['Surname']\n",
    "\n",
    "df.Gender[df.Gender == 'Male'] = 1\n",
    "df.Gender[df.Gender == 'Female'] = 0\n",
    "\n",
    "expl = ['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "x = df[expl]\n",
    "y = df[['Exited']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michi\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:921: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = inf\n",
      "Iteration 2, loss = inf\n",
      "Iteration 3, loss = inf\n",
      "Iteration 4, loss = inf\n",
      "Iteration 5, loss = inf\n",
      "Iteration 6, loss = inf\n",
      "Iteration 7, loss = inf\n",
      "Iteration 8, loss = inf\n",
      "Iteration 9, loss = inf\n",
      "Iteration 10, loss = inf\n",
      "Iteration 11, loss = inf\n",
      "Iteration 12, loss = inf\n",
      "Iteration 13, loss = inf\n",
      "Iteration 14, loss = inf\n",
      "Iteration 15, loss = inf\n",
      "Iteration 16, loss = inf\n",
      "Iteration 17, loss = inf\n",
      "Iteration 18, loss = inf\n",
      "Iteration 19, loss = inf\n",
      "Iteration 20, loss = inf\n",
      "Iteration 21, loss = inf\n",
      "Iteration 22, loss = inf\n",
      "Iteration 23, loss = inf\n",
      "Iteration 24, loss = inf\n",
      "Iteration 25, loss = inf\n",
      "Iteration 26, loss = inf\n",
      "Iteration 27, loss = inf\n",
      "Iteration 28, loss = inf\n",
      "Iteration 29, loss = inf\n",
      "Iteration 30, loss = inf\n",
      "Iteration 31, loss = inf\n",
      "Iteration 32, loss = inf\n",
      "Iteration 33, loss = inf\n",
      "Iteration 34, loss = inf\n",
      "Iteration 35, loss = inf\n",
      "Iteration 36, loss = inf\n",
      "Iteration 37, loss = inf\n",
      "Iteration 38, loss = inf\n",
      "Iteration 39, loss = inf\n",
      "Iteration 40, loss = inf\n",
      "Iteration 41, loss = inf\n",
      "Iteration 42, loss = inf\n",
      "Iteration 43, loss = inf\n",
      "Iteration 44, loss = inf\n",
      "Iteration 45, loss = inf\n",
      "Iteration 46, loss = inf\n",
      "Iteration 47, loss = inf\n",
      "Iteration 48, loss = inf\n",
      "Iteration 49, loss = inf\n",
      "Iteration 50, loss = inf\n",
      "Iteration 51, loss = inf\n",
      "Iteration 52, loss = inf\n",
      "Iteration 53, loss = inf\n",
      "Iteration 54, loss = inf\n",
      "Iteration 55, loss = inf\n",
      "Iteration 56, loss = inf\n",
      "Iteration 57, loss = inf\n",
      "Iteration 58, loss = inf\n",
      "Iteration 59, loss = inf\n",
      "Iteration 60, loss = inf\n",
      "Iteration 61, loss = inf\n",
      "Iteration 62, loss = inf\n",
      "Iteration 63, loss = inf\n",
      "Iteration 64, loss = inf\n",
      "Iteration 65, loss = inf\n",
      "Iteration 66, loss = inf\n",
      "Iteration 67, loss = inf\n",
      "Iteration 68, loss = inf\n",
      "Iteration 69, loss = inf\n",
      "Iteration 70, loss = inf\n",
      "Iteration 71, loss = inf\n",
      "Iteration 72, loss = inf\n",
      "Iteration 73, loss = inf\n",
      "Iteration 74, loss = inf\n",
      "Iteration 75, loss = inf\n",
      "Iteration 76, loss = inf\n",
      "Iteration 77, loss = inf\n",
      "Iteration 78, loss = inf\n",
      "Iteration 79, loss = inf\n",
      "Iteration 80, loss = inf\n",
      "Iteration 81, loss = inf\n",
      "Iteration 82, loss = inf\n",
      "Iteration 83, loss = inf\n",
      "Iteration 84, loss = inf\n",
      "Iteration 85, loss = inf\n",
      "Iteration 86, loss = inf\n",
      "Iteration 87, loss = inf\n",
      "Iteration 88, loss = inf\n",
      "Iteration 89, loss = inf\n",
      "Iteration 90, loss = inf\n",
      "Iteration 91, loss = inf\n",
      "Iteration 92, loss = inf\n",
      "Iteration 93, loss = inf\n",
      "Iteration 94, loss = inf\n",
      "Iteration 95, loss = inf\n",
      "Iteration 96, loss = inf\n",
      "Iteration 97, loss = inf\n",
      "Iteration 98, loss = inf\n",
      "Iteration 99, loss = inf\n",
      "Iteration 100, loss = inf\n",
      "Iteration 101, loss = inf\n",
      "Iteration 102, loss = inf\n",
      "Iteration 103, loss = inf\n",
      "Iteration 104, loss = inf\n",
      "Iteration 105, loss = inf\n",
      "Iteration 106, loss = inf\n",
      "Iteration 107, loss = inf\n",
      "Iteration 108, loss = inf\n",
      "Iteration 109, loss = inf\n",
      "Iteration 110, loss = inf\n",
      "Iteration 111, loss = inf\n",
      "Iteration 112, loss = inf\n",
      "Iteration 113, loss = inf\n",
      "Iteration 114, loss = inf\n",
      "Iteration 115, loss = inf\n",
      "Iteration 116, loss = inf\n",
      "Iteration 117, loss = inf\n",
      "Iteration 118, loss = inf\n",
      "Iteration 119, loss = inf\n",
      "Iteration 120, loss = inf\n",
      "Iteration 121, loss = inf\n",
      "Iteration 122, loss = inf\n",
      "Iteration 123, loss = inf\n",
      "Iteration 124, loss = inf\n",
      "Iteration 125, loss = inf\n",
      "Iteration 126, loss = inf\n",
      "Iteration 127, loss = inf\n",
      "Iteration 128, loss = 3.48299211\n",
      "Iteration 129, loss = inf\n",
      "Iteration 130, loss = inf\n",
      "Iteration 131, loss = inf\n",
      "Iteration 132, loss = inf\n",
      "Iteration 133, loss = 1.61894034\n",
      "Iteration 134, loss = inf\n",
      "Iteration 135, loss = 1.28789494\n",
      "Iteration 136, loss = 1.25666059\n",
      "Iteration 137, loss = inf\n",
      "Iteration 138, loss = inf\n",
      "Iteration 139, loss = inf\n",
      "Iteration 140, loss = 1.59352200\n",
      "Iteration 141, loss = 1.60931536\n",
      "Iteration 142, loss = 1.71090554\n",
      "Iteration 143, loss = 1.88013234\n",
      "Iteration 144, loss = 1.31985864\n",
      "Iteration 145, loss = 0.73099627\n",
      "Iteration 146, loss = 0.98821011\n",
      "Iteration 147, loss = 0.88745036\n",
      "Iteration 148, loss = 0.91859831\n",
      "Iteration 149, loss = 1.16392499\n",
      "Iteration 150, loss = 1.41000017\n",
      "Iteration 151, loss = 0.85697499\n",
      "Iteration 152, loss = 0.98403523\n",
      "Iteration 153, loss = 1.07162776\n",
      "Iteration 154, loss = 0.97321606\n",
      "Iteration 155, loss = 0.72707746\n",
      "Iteration 156, loss = 0.79959030\n",
      "Iteration 157, loss = 0.80512442\n",
      "Iteration 158, loss = 0.94431764\n",
      "Iteration 159, loss = 0.65980792\n",
      "Iteration 160, loss = 0.82213260\n",
      "Iteration 161, loss = 0.56086683\n",
      "Iteration 162, loss = 0.64967284\n",
      "Iteration 163, loss = 0.66991282\n",
      "Iteration 164, loss = 0.67688480\n",
      "Iteration 165, loss = 0.71404144\n",
      "Iteration 166, loss = 0.80519381\n",
      "Iteration 167, loss = 0.60623616\n",
      "Iteration 168, loss = 0.72685085\n",
      "Iteration 169, loss = 0.56769236\n",
      "Iteration 170, loss = 0.53854593\n",
      "Iteration 171, loss = 0.54675041\n",
      "Iteration 172, loss = 0.59615227\n",
      "Iteration 173, loss = 0.51143815\n",
      "Iteration 174, loss = 0.58323841\n",
      "Iteration 175, loss = 0.53119451\n",
      "Iteration 176, loss = 0.57902112\n",
      "Iteration 177, loss = 0.63563614\n",
      "Iteration 178, loss = 0.55206447\n",
      "Iteration 179, loss = 0.51041460\n",
      "Iteration 180, loss = 0.49763453\n",
      "Iteration 181, loss = 0.49861709\n",
      "Iteration 182, loss = 0.49395452\n",
      "Iteration 183, loss = 0.50191395\n",
      "Iteration 184, loss = 0.49116118\n",
      "Iteration 185, loss = 0.51421805\n",
      "Iteration 186, loss = 0.50875776\n",
      "Iteration 187, loss = 0.49417754\n",
      "Iteration 188, loss = 0.48703511\n",
      "Iteration 189, loss = 0.49678450\n",
      "Iteration 190, loss = 0.48785465\n",
      "Iteration 191, loss = 0.48614987\n",
      "Iteration 192, loss = 0.50179292\n",
      "Iteration 193, loss = 0.49019170\n",
      "Iteration 194, loss = 0.49250651\n",
      "Iteration 195, loss = 0.49148082\n",
      "Iteration 196, loss = 0.50593096\n",
      "Iteration 197, loss = 0.51861313\n",
      "Iteration 198, loss = 0.49207853\n",
      "Iteration 199, loss = 0.48911526\n",
      "Iteration 200, loss = 0.50204269\n",
      "Iteration 201, loss = 0.49350589\n",
      "Iteration 202, loss = 0.49122719\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Testing Accuracy: 0.7905\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes = [5], activation='relu', solver='adam', learning_rate_init = 0.01, max_iter = 1000, verbose = True)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, clf.predict(x_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michi\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.8505\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(x_train, y_train)\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, rfc.predict(x_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michi\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "lr.fit(x_train, y_train)\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = inf\n",
      "Iteration 2, loss = inf\n",
      "Iteration 3, loss = inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michi\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\michi\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = inf\n",
      "Iteration 5, loss = inf\n",
      "Iteration 6, loss = inf\n",
      "Iteration 7, loss = inf\n",
      "Iteration 8, loss = inf\n",
      "Iteration 9, loss = inf\n",
      "Iteration 10, loss = inf\n",
      "Iteration 11, loss = inf\n",
      "Iteration 12, loss = inf\n",
      "Iteration 13, loss = inf\n",
      "Iteration 14, loss = inf\n",
      "Iteration 15, loss = inf\n",
      "Iteration 16, loss = inf\n",
      "Iteration 17, loss = inf\n",
      "Iteration 18, loss = inf\n",
      "Iteration 19, loss = inf\n",
      "Iteration 20, loss = inf\n",
      "Iteration 21, loss = inf\n",
      "Iteration 22, loss = inf\n",
      "Iteration 23, loss = inf\n",
      "Iteration 24, loss = inf\n",
      "Iteration 25, loss = inf\n",
      "Iteration 26, loss = inf\n",
      "Iteration 27, loss = inf\n",
      "Iteration 28, loss = inf\n",
      "Iteration 29, loss = inf\n",
      "Iteration 30, loss = inf\n",
      "Iteration 31, loss = inf\n",
      "Iteration 32, loss = inf\n",
      "Iteration 33, loss = inf\n",
      "Iteration 34, loss = inf\n",
      "Iteration 35, loss = inf\n",
      "Iteration 36, loss = inf\n",
      "Iteration 37, loss = inf\n",
      "Iteration 38, loss = inf\n",
      "Iteration 39, loss = inf\n",
      "Iteration 40, loss = inf\n",
      "Iteration 41, loss = inf\n",
      "Iteration 42, loss = inf\n",
      "Iteration 43, loss = inf\n",
      "Iteration 44, loss = inf\n",
      "Iteration 45, loss = inf\n",
      "Iteration 46, loss = inf\n",
      "Iteration 47, loss = inf\n",
      "Iteration 48, loss = inf\n",
      "Iteration 49, loss = inf\n",
      "Iteration 50, loss = inf\n",
      "Iteration 51, loss = inf\n",
      "Iteration 52, loss = inf\n",
      "Iteration 53, loss = inf\n",
      "Iteration 54, loss = inf\n",
      "Iteration 55, loss = inf\n",
      "Iteration 56, loss = inf\n",
      "Iteration 57, loss = inf\n",
      "Iteration 58, loss = inf\n",
      "Iteration 59, loss = inf\n",
      "Iteration 60, loss = inf\n",
      "Iteration 61, loss = inf\n",
      "Iteration 62, loss = inf\n",
      "Iteration 63, loss = inf\n",
      "Iteration 64, loss = inf\n",
      "Iteration 65, loss = inf\n",
      "Iteration 66, loss = inf\n",
      "Iteration 67, loss = inf\n",
      "Iteration 68, loss = inf\n",
      "Iteration 69, loss = inf\n",
      "Iteration 70, loss = inf\n",
      "Iteration 71, loss = inf\n",
      "Iteration 72, loss = inf\n",
      "Iteration 73, loss = inf\n",
      "Iteration 74, loss = inf\n",
      "Iteration 75, loss = inf\n",
      "Iteration 76, loss = inf\n",
      "Iteration 77, loss = inf\n",
      "Iteration 78, loss = inf\n",
      "Iteration 79, loss = inf\n",
      "Iteration 80, loss = inf\n",
      "Iteration 81, loss = inf\n",
      "Iteration 82, loss = inf\n",
      "Iteration 83, loss = inf\n",
      "Iteration 84, loss = inf\n",
      "Iteration 85, loss = inf\n",
      "Iteration 86, loss = inf\n",
      "Iteration 87, loss = inf\n",
      "Iteration 88, loss = inf\n",
      "Iteration 89, loss = inf\n",
      "Iteration 90, loss = inf\n",
      "Iteration 91, loss = inf\n",
      "Iteration 92, loss = inf\n",
      "Iteration 93, loss = inf\n",
      "Iteration 94, loss = inf\n",
      "Iteration 95, loss = inf\n",
      "Iteration 96, loss = inf\n",
      "Iteration 97, loss = inf\n",
      "Iteration 98, loss = inf\n",
      "Iteration 99, loss = inf\n",
      "Iteration 100, loss = inf\n",
      "Iteration 101, loss = inf\n",
      "Iteration 102, loss = inf\n",
      "Iteration 103, loss = inf\n",
      "Iteration 104, loss = inf\n",
      "Iteration 105, loss = inf\n",
      "Iteration 106, loss = inf\n",
      "Iteration 107, loss = inf\n",
      "Iteration 108, loss = inf\n",
      "Iteration 109, loss = inf\n",
      "Iteration 110, loss = inf\n",
      "Iteration 111, loss = inf\n",
      "Iteration 112, loss = inf\n",
      "Iteration 113, loss = inf\n",
      "Iteration 114, loss = inf\n",
      "Iteration 115, loss = inf\n",
      "Iteration 116, loss = inf\n",
      "Iteration 117, loss = inf\n",
      "Iteration 118, loss = inf\n",
      "Iteration 119, loss = inf\n",
      "Iteration 120, loss = inf\n",
      "Iteration 121, loss = inf\n",
      "Iteration 122, loss = inf\n",
      "Iteration 123, loss = inf\n",
      "Iteration 124, loss = inf\n",
      "Iteration 125, loss = inf\n",
      "Iteration 126, loss = inf\n",
      "Iteration 127, loss = inf\n",
      "Iteration 128, loss = inf\n",
      "Iteration 129, loss = inf\n",
      "Iteration 130, loss = inf\n",
      "Iteration 131, loss = inf\n",
      "Iteration 132, loss = inf\n",
      "Iteration 133, loss = inf\n",
      "Iteration 134, loss = inf\n",
      "Iteration 135, loss = inf\n",
      "Iteration 136, loss = inf\n",
      "Iteration 137, loss = inf\n",
      "Iteration 138, loss = inf\n",
      "Iteration 139, loss = inf\n",
      "Iteration 140, loss = inf\n",
      "Iteration 141, loss = inf\n",
      "Iteration 142, loss = inf\n",
      "Iteration 143, loss = inf\n",
      "Iteration 144, loss = inf\n",
      "Iteration 145, loss = inf\n",
      "Iteration 146, loss = inf\n",
      "Iteration 147, loss = inf\n",
      "Iteration 148, loss = inf\n",
      "Iteration 149, loss = inf\n",
      "Iteration 150, loss = inf\n",
      "Iteration 151, loss = inf\n",
      "Iteration 152, loss = inf\n",
      "Iteration 153, loss = inf\n",
      "Iteration 154, loss = inf\n",
      "Iteration 155, loss = inf\n",
      "Iteration 156, loss = inf\n",
      "Iteration 157, loss = inf\n",
      "Iteration 158, loss = inf\n",
      "Iteration 159, loss = inf\n",
      "Iteration 160, loss = inf\n",
      "Iteration 161, loss = inf\n",
      "Iteration 162, loss = inf\n",
      "Iteration 163, loss = inf\n",
      "Iteration 164, loss = inf\n",
      "Iteration 165, loss = inf\n",
      "Iteration 166, loss = inf\n",
      "Iteration 167, loss = inf\n",
      "Iteration 168, loss = inf\n",
      "Iteration 169, loss = inf\n",
      "Iteration 170, loss = inf\n",
      "Iteration 171, loss = inf\n",
      "Iteration 172, loss = inf\n",
      "Iteration 173, loss = inf\n",
      "Iteration 174, loss = inf\n",
      "Iteration 175, loss = inf\n",
      "Iteration 176, loss = inf\n",
      "Iteration 177, loss = inf\n",
      "Iteration 178, loss = inf\n",
      "Iteration 179, loss = inf\n",
      "Iteration 180, loss = inf\n",
      "Iteration 181, loss = inf\n",
      "Iteration 182, loss = inf\n",
      "Iteration 183, loss = inf\n",
      "Iteration 184, loss = inf\n",
      "Iteration 185, loss = inf\n",
      "Iteration 186, loss = inf\n",
      "Iteration 187, loss = inf\n",
      "Iteration 188, loss = inf\n",
      "Iteration 189, loss = inf\n",
      "Iteration 190, loss = inf\n",
      "Iteration 191, loss = inf\n",
      "Iteration 192, loss = inf\n",
      "Iteration 193, loss = inf\n",
      "Iteration 194, loss = inf\n",
      "Iteration 195, loss = inf\n",
      "Iteration 196, loss = inf\n",
      "Iteration 197, loss = inf\n",
      "Iteration 198, loss = inf\n",
      "Iteration 199, loss = inf\n",
      "Iteration 200, loss = inf\n",
      "Iteration 201, loss = inf\n",
      "Iteration 202, loss = inf\n",
      "Iteration 203, loss = inf\n",
      "Iteration 204, loss = inf\n",
      "Iteration 205, loss = inf\n",
      "Iteration 206, loss = inf\n",
      "Iteration 207, loss = inf\n",
      "Iteration 208, loss = inf\n",
      "Iteration 209, loss = inf\n",
      "Iteration 210, loss = inf\n",
      "Iteration 211, loss = inf\n",
      "Iteration 212, loss = inf\n",
      "Iteration 213, loss = inf\n",
      "Iteration 214, loss = inf\n",
      "Iteration 215, loss = inf\n",
      "Iteration 216, loss = inf\n",
      "Iteration 217, loss = inf\n",
      "Iteration 218, loss = inf\n",
      "Iteration 219, loss = inf\n",
      "Iteration 220, loss = inf\n",
      "Iteration 221, loss = inf\n",
      "Iteration 222, loss = inf\n",
      "Iteration 223, loss = inf\n",
      "Iteration 224, loss = inf\n",
      "Iteration 225, loss = inf\n",
      "Iteration 226, loss = inf\n",
      "Iteration 227, loss = inf\n",
      "Iteration 228, loss = inf\n",
      "Iteration 229, loss = inf\n",
      "Iteration 230, loss = inf\n",
      "Iteration 231, loss = inf\n",
      "Iteration 232, loss = inf\n",
      "Iteration 233, loss = inf\n",
      "Iteration 234, loss = inf\n",
      "Iteration 235, loss = inf\n",
      "Iteration 236, loss = inf\n",
      "Iteration 237, loss = inf\n",
      "Iteration 238, loss = inf\n",
      "Iteration 239, loss = inf\n",
      "Iteration 240, loss = inf\n",
      "Iteration 241, loss = inf\n",
      "Iteration 242, loss = inf\n",
      "Iteration 243, loss = inf\n",
      "Iteration 244, loss = inf\n",
      "Iteration 245, loss = inf\n",
      "Iteration 246, loss = inf\n",
      "Iteration 247, loss = inf\n",
      "Iteration 248, loss = inf\n",
      "Iteration 249, loss = inf\n",
      "Iteration 250, loss = inf\n",
      "Iteration 251, loss = inf\n",
      "Iteration 252, loss = inf\n",
      "Iteration 253, loss = inf\n",
      "Iteration 254, loss = inf\n",
      "Iteration 255, loss = inf\n",
      "Iteration 256, loss = inf\n",
      "Iteration 257, loss = inf\n",
      "Iteration 258, loss = inf\n",
      "Iteration 259, loss = inf\n",
      "Iteration 260, loss = inf\n",
      "Iteration 261, loss = inf\n",
      "Iteration 262, loss = inf\n",
      "Iteration 263, loss = inf\n",
      "Iteration 264, loss = inf\n",
      "Iteration 265, loss = inf\n",
      "Iteration 266, loss = inf\n",
      "Iteration 267, loss = inf\n",
      "Iteration 268, loss = inf\n",
      "Iteration 269, loss = inf\n",
      "Iteration 270, loss = inf\n",
      "Iteration 271, loss = inf\n",
      "Iteration 272, loss = inf\n",
      "Iteration 273, loss = inf\n",
      "Iteration 274, loss = inf\n",
      "Iteration 275, loss = inf\n",
      "Iteration 276, loss = inf\n",
      "Iteration 277, loss = inf\n",
      "Iteration 278, loss = inf\n",
      "Iteration 279, loss = inf\n",
      "Iteration 280, loss = inf\n",
      "Iteration 281, loss = inf\n",
      "Iteration 282, loss = inf\n",
      "Iteration 283, loss = inf\n",
      "Iteration 284, loss = inf\n",
      "Iteration 285, loss = inf\n",
      "Iteration 286, loss = inf\n",
      "Iteration 287, loss = inf\n",
      "Iteration 288, loss = inf\n",
      "Iteration 289, loss = inf\n",
      "Iteration 290, loss = inf\n",
      "Iteration 291, loss = inf\n",
      "Iteration 292, loss = inf\n",
      "Iteration 293, loss = inf\n",
      "Iteration 294, loss = inf\n",
      "Iteration 295, loss = inf\n",
      "Iteration 296, loss = inf\n",
      "Iteration 297, loss = inf\n",
      "Iteration 298, loss = inf\n",
      "Iteration 299, loss = inf\n",
      "Iteration 300, loss = inf\n",
      "Iteration 301, loss = inf\n",
      "Iteration 302, loss = inf\n",
      "Iteration 303, loss = inf\n",
      "Iteration 304, loss = inf\n",
      "Iteration 305, loss = inf\n",
      "Iteration 306, loss = inf\n",
      "Iteration 307, loss = inf\n",
      "Iteration 308, loss = inf\n",
      "Iteration 309, loss = inf\n",
      "Iteration 310, loss = inf\n",
      "Iteration 311, loss = inf\n",
      "Iteration 312, loss = inf\n",
      "Iteration 313, loss = inf\n",
      "Iteration 314, loss = inf\n",
      "Iteration 315, loss = inf\n",
      "Iteration 316, loss = inf\n",
      "Iteration 317, loss = inf\n",
      "Iteration 318, loss = inf\n",
      "Iteration 319, loss = inf\n",
      "Iteration 320, loss = inf\n",
      "Iteration 321, loss = inf\n",
      "Iteration 322, loss = inf\n",
      "Iteration 323, loss = inf\n",
      "Iteration 324, loss = inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 325, loss = inf\n",
      "Iteration 326, loss = inf\n",
      "Iteration 327, loss = inf\n",
      "Iteration 328, loss = inf\n",
      "Iteration 329, loss = inf\n",
      "Iteration 330, loss = inf\n",
      "Iteration 331, loss = inf\n",
      "Iteration 332, loss = inf\n",
      "Iteration 333, loss = inf\n",
      "Iteration 334, loss = inf\n",
      "Iteration 335, loss = inf\n",
      "Iteration 336, loss = inf\n",
      "Iteration 337, loss = inf\n",
      "Iteration 338, loss = inf\n",
      "Iteration 339, loss = inf\n",
      "Iteration 340, loss = inf\n",
      "Iteration 341, loss = inf\n",
      "Iteration 342, loss = inf\n",
      "Iteration 343, loss = inf\n",
      "Iteration 344, loss = inf\n",
      "Iteration 345, loss = inf\n",
      "Iteration 346, loss = inf\n",
      "Iteration 347, loss = inf\n",
      "Iteration 348, loss = inf\n",
      "Iteration 349, loss = inf\n",
      "Iteration 350, loss = inf\n",
      "Iteration 351, loss = inf\n",
      "Iteration 352, loss = inf\n",
      "Iteration 353, loss = inf\n",
      "Iteration 354, loss = inf\n",
      "Iteration 355, loss = inf\n",
      "Iteration 356, loss = 1.08540020\n",
      "Iteration 357, loss = 1.24822849\n",
      "Iteration 358, loss = inf\n",
      "Iteration 359, loss = inf\n",
      "Iteration 360, loss = 1.53782673\n",
      "Iteration 361, loss = inf\n",
      "Iteration 362, loss = inf\n",
      "Iteration 363, loss = inf\n",
      "Iteration 364, loss = 1.39207925\n",
      "Iteration 365, loss = inf\n",
      "Iteration 366, loss = inf\n",
      "Iteration 367, loss = 0.90365661\n",
      "Iteration 368, loss = 1.11479098\n",
      "Iteration 369, loss = inf\n",
      "Iteration 370, loss = inf\n",
      "Iteration 371, loss = 0.86531220\n",
      "Iteration 372, loss = 0.88832956\n",
      "Iteration 373, loss = inf\n",
      "Iteration 374, loss = 1.11477855\n",
      "Iteration 375, loss = inf\n",
      "Iteration 376, loss = 1.41191374\n",
      "Iteration 377, loss = 0.89060689\n",
      "Iteration 378, loss = 1.59937974\n",
      "Iteration 379, loss = inf\n",
      "Iteration 380, loss = inf\n",
      "Iteration 381, loss = inf\n",
      "Iteration 382, loss = inf\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Testing Accuracy: 0.7995\n"
     ]
    }
   ],
   "source": [
    "vc = VotingClassifier(estimators=[('clf', clf), ('rfc', rfc), ('lr', lr)], voting='hard')\n",
    "vc.fit(x_train, y_train)\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, vc.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
